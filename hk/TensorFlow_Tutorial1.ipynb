{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This tutorial comes from TensorFlow\n",
    "#Deep MNIST for Experts\n",
    "#The link is as follows: https://www.tensorflow.org/versions/0.6.0/tutorials/mnist/pros/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST Data\n",
    "import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Start TensorFlow InteractiveSession\n",
    "Tensorflow relies on a highly efficient C++ backend to do its computation. \n",
    "The connection to this backend is called a session.\n",
    "The common usage for TensorFlow programs is to first create a graph and then launch it in a session.\n",
    "Here we instead use the convenient InteractiveSession class, which makes TensorFlow more flexible about how you structure your code.\n",
    "It allows you to interleave operations which build a computation graph with ones that run the graph.\n",
    "This is particularly convenient when working in interactive contexts like iPython. \n",
    "If you are not using an InteractiveSession, then you should build the entire computation graph before starting a session and launching the graph.\n",
    "'''\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build a Softmax Regression Model\n",
    "'''\n",
    "Here x and y_ aren't specific values.\n",
    "Rather, they are each a placeholder -- a value that we'll input when we ask TensorFlow to run a computation.\n",
    "The input images x will consist of a 2d tensor of floating point numbers. \n",
    "Here we assign it a shape of [None, 784], where 784 is the dimensionality of a single flattened MNIST image,\n",
    "and None indicates that the first dimension, corresponding to the batch size, can be of any size. \n",
    "The target output classes y_ will also consist of a 2d tensor, where each row is a one-hot 10-dimensional vector indicating which digit class the corresponding MNIST image belongs to.\n",
    "The shape argument to placeholder is optional, but it allows TensorFlow to automatically catch bugs stemming from inconsistent tensor shapes\n",
    "'''\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variables\n",
    "'''\n",
    "We now define the weights W and biases b for our model. \n",
    "We could imagine treating these like additional inputs, \n",
    "but TensorFlow has an even better way to handle them: Variable. \n",
    "A Variable is a value that lives in TensorFlow's computation graph. \n",
    "It can be used and even modified by the computation. \n",
    "In machine learning applications, one generally has the model paramaters be Variables.\n",
    "'''\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "'''\n",
    "We pass the initial value for each parameter in the call to tf.Variable. \n",
    "In this case, we initialize both W and b as tensors full of zeros. \n",
    "W is a 784x10 matrix (because we have 784 input features and 10 outputs) and b is a 10-dimensional vector (because we have 10 classes).\n",
    "Before Variables can be used within a session, they must be initialized using that session. \n",
    "This step takes the initial values (in this case tensors full of zeros) that have already been specified, and assigns them to each Variable. \n",
    "This can be done for all Variables at once.\n",
    "'''\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicted Class and Cost Function\n",
    "'''\n",
    "We can now implement our regression model.\n",
    "It only takes one line! We multiply the vectorized input images x by the weight matrix W, \n",
    "add the bias b, and compute the softmax probabilities that are assigned to each class.\n",
    "\n",
    "The cost function to be minimized during training can be specified just as easily. \n",
    "Our cost function will be the cross-entropy between the target and the model's prediction.\n",
    "'''\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train the Model\n",
    "'''\n",
    "Now that we have defined our model and training cost function, it is straightforward to train using TensorFlow.\n",
    "Because TensorFlow knows the entire computation graph, it can use automatic differentiation to find the gradients of the cost with respect to each of the variables.\n",
    "TensorFlow has a variety of builtin optimization algorithms.\n",
    "For this example, we will use steepest gradient descent, with a step length of 0.01, to descend the cross entropy\n",
    "'''\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "for i in range(1000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the Model\n",
    "'''\n",
    "How well did our model do?\n",
    "\n",
    "First we'll figure out where we predicted the correct label. \n",
    "tf.argmax is an extremely useful function which gives you the index of the highest entry in a tensor along some axis.\n",
    "For example, tf.argmax(y,1) is the label our model thinks is most likely for each input, while tf.argmax(y_,1) is the true label. \n",
    "We can use tf.equal to check if our prediction matches the truth.\n",
    "'''\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "#That gives us a list of booleans. To determine what fraction are correct, we cast to floating point numbers and then take the mean.\n",
    "#For example, [True, False, True, True] would become [1,0,1,1] which would become 0.75.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
